{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17a2b4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 10, 'train_auc': 0.6890240560991914, 'val_auc': 0.6876221862538593}\n",
      "{'epoch': 20, 'train_auc': 0.6906825378883971, 'val_auc': 0.6894832598913301}\n",
      "{'epoch': 30, 'train_auc': 0.6936672061619087, 'val_auc': 0.6930791091016655}\n",
      "{'epoch': 40, 'train_auc': 0.6913650786015225, 'val_auc': 0.6891752669335156}\n",
      "EarlyStopping!!!\n",
      "['train_auc', 'val_auc']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import recall_score, roc_auc_score, accuracy_score\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore') # 关闭警告\n",
    "\n",
    "def create_dataloader(X, y, batch_size=1, shuffle=True): # 创建batch迭代器函数\n",
    "    torch_dataset = TensorDataset(X, y)\n",
    "    loader = DataLoader(dataset=torch_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    return loader\n",
    "\n",
    "\n",
    "def get_loss(task): # 获取损失函数\n",
    "    if task == \"binary\":\n",
    "        criterion = torch.nn.BCELoss() # 注：此损失函数要求：1.每个样本只能有一个概率值，即输出是1 dim的tensor；2.要求标签是float类型\n",
    "    elif task == \"multiclass\":\n",
    "        criterion = torch.nn.CrossEntropyLoss() # 注：此损失函数要求：1.每个样本必须有每个类别的概率，即便是2分类，即输出是2 dim的tensor；2.要求标签是long类型\n",
    "    elif task == \"regression_1\":\n",
    "        criterion = torch.nn.L1Loss()\n",
    "    elif task == \"regression_2\":\n",
    "        criterion = torch.nn.MSELoss()\n",
    "    else:\n",
    "        raise ValueError(\"Please input correct value!!!\")\n",
    "    return criterion\n",
    "\n",
    "\n",
    "def get_optimizer(params, opt_criterion, learning_rate, l2): # 获取梯度优化器函数\n",
    "    if learning_rate <= 0 or l2 < 0: \n",
    "        raise ValueError(\"Please input correct learning_rate and l2!!!\")\n",
    "    if opt_criterion.lower() == \"adam\":\n",
    "        optimizer = torch.optim.Adam(params, lr=learning_rate, weight_decay=l2)\n",
    "    elif opt_criterion.lower() == \"adagrad\":\n",
    "        optimizer = torch.optim.Adagrad(params, lr=learning_rate, weight_decay=l2)\n",
    "    elif opt_criterion.lower() == \"rmsprop\":\n",
    "        optimizer = torch.optim.RMSprop(params, lr=learning_rate, weight_decay=l2)\n",
    "    elif opt_criterion.lower() == \"sgd\":\n",
    "        optimizer = torch.optim.SGD(params, lr=learning_rate, weight_decay=l2)\n",
    "    else:\n",
    "        raise ValueError(\"Please input correct opt_criterion!!!\")\n",
    "    return optimizer\n",
    "\n",
    "def weight_init(m): # 网络参数初始化函数\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        torch.nn.init.constant_(m.weight, 1)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "\n",
    "def seed_torch(seed=2022): # 固定所有随机种子函数\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) # 为了禁止hash随机化，使得实验可复现\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "\n",
    "# 预测/验证函数\n",
    "def predict_model(model, test_X, test_y = None, batch_size=1, task=None, metrics=None, device=\"cpu\"): # 有test_y时验证，没有时预测\n",
    "    test_loader = create_dataloader(test_X, test_y, batch_size=batch_size, shuffle=False)\n",
    "    loss_func = get_loss(task)\n",
    "    model = model.eval()\n",
    "    pred_ans, loss = [], 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device).float()\n",
    "            target = target.to(device).float().squeeze()\n",
    "            output = model(data).squeeze(dim=-1)\n",
    "            pred_ans.append(output.cpu().data.numpy())\n",
    "            loss += loss_func(output, target).item()\n",
    "    y_pred = np.concatenate(pred_ans).astype(\"float64\")\n",
    "    \n",
    "    if test_y is not None:\n",
    "        metrics_d = {}\n",
    "        for i in metrics:\n",
    "            if \"auc\" in i:\n",
    "                metrics_d[\"auc\"] = roc_auc_score(test_y.squeeze().data.numpy(), y_pred) # roc_auc_score的真实标签必须在前面\n",
    "            elif \"loss\" in i:\n",
    "                metrics_d[\"loss\"] = loss/len(y_pred)\n",
    "        return metrics_d\n",
    "    else:\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "def train_model(model, X, y, valid_data=None, valid_split=0., batch_size=1, opt_criterion=\"adam\", task=\"binary\", \\\n",
    "                metrics=[\"loss\",\"auc\"], eval_metric=\"auc\", epochs=100, early_stopping_bounds=None, seed=2022, \\\n",
    "                learning_rate=0.01, l2=0.01, shuffle=True, save_path=None, device=\"cpu\", verbose=0, is_plt=True):\n",
    "    \n",
    "    # 固定随机数种子\n",
    "    seed_torch(seed=seed)\n",
    "    \n",
    "    # 模型设置\n",
    "    model = model.to(device) # 将参数部署到指定设备\n",
    "    model.apply(weight_init) # 初始化参数\n",
    "    loss_func = get_loss(task) # 获取损失函数\n",
    "    optimizer = get_optimizer(model.parameters(), opt_criterion, learning_rate, l2) # 获取梯度优化器\n",
    "    \n",
    "    # 数据设置\n",
    "    X, y = torch.tensor(X), torch.tensor(y).unsqueeze(dim=1) # 将numpy的输入转为tensor，记得要将标签升维用以切分数据集，后面再降为1dim\n",
    "    if valid_data and len(valid_data) == 2: # 优先自主设置验证集\n",
    "        train_loader = create_dataloader(X, y, batch_size=batch_size, shuffle=shuffle)\n",
    "        val_X, val_y = valid_data[0], valid_data[1]\n",
    "        valid_loader = create_dataloader(val_X, val_y, batch_size=batch_size, shuffle=shuffle)\n",
    "    elif 1 > valid_split > 0: # 从数据中拆分验证集\n",
    "        len_data = list(range(X.shape[0]))\n",
    "        np.random.shuffle(len_data)\n",
    "        train_index, valid_index = len_data[:int((1-valid_split)*X.shape[0])], len_data[int((1-valid_split)*X.shape[0]):] # 获取训练集和验证集各自索引列表\n",
    "        X, val_X, y, val_y = X[train_index], X[valid_index], y[train_index], y[valid_index]\n",
    "        train_loader = create_dataloader(X, y, batch_size=batch_size, shuffle=shuffle)\n",
    "        valid_loader = create_dataloader(val_X, val_y, batch_size=batch_size, shuffle=shuffle)\n",
    "    elif valid_split == 0: # 如果不设置验证集\n",
    "        train_loader = create_dataloader(X, y, batch_size=batch_size, shuffle=shuffle)\n",
    "        valid_loader = None\n",
    "    else:\n",
    "        raise ValueError(\"Please input correct valid_dataset!!!\")\n",
    "\n",
    "    # 训练模型\n",
    "    metrics_total = [] # 所有迭代次数指标结果集合\n",
    "    metrics_dict = {} # 每个epoch指标结果\n",
    "    if eval_metric or save_path: # 如果使用早停或者要保存参数\n",
    "        if eval_metric not in [\"auc\", \"loss\", None]:\n",
    "                raise ValueError(\"Please input correct eval_metric!!!!\")\n",
    "        threshold = float(\"inf\") # 早停阈值（实时更新）\n",
    "        cnt = 0 # 早停计数器\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        metrics_dict[\"epoch\"] = epoch\n",
    "        \n",
    "        # 训练\n",
    "        model = model.train()\n",
    "        for data, target in train_loader:\n",
    "            data = data.to(device).float()\n",
    "            target = target.to(device).float().squeeze() # 标签后面做运算时候必须是1dim\n",
    "            output = model(data).squeeze(dim=-1) # 如果是二分类或回归，输出必须是1dim，如果是多分类，dim=-1不会改变输出\n",
    "            loss = loss_func(output, target)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10, norm_type=2) # 梯度裁剪，参数介绍：参数集合；最大梯度范数；梯度范数类型\n",
    "            optimizer.step()\n",
    "            \n",
    "        # 训练集指标获取\n",
    "        metric_train_dict = predict_model(model, X, y, batch_size=batch_size, task=task, metrics=metrics, device=device)\n",
    "        for i in metric_train_dict: metrics_dict[\"train_\"+i] = metric_train_dict[i]\n",
    "        if not valid_loader: \n",
    "            if verbose > 0 and epoch % verbose == 0: print(metrics_dict) # 如果不需要验证直接输出指标结果\n",
    "            metrics_total.append(metrics_dict) # 记录指标结果\n",
    "        \n",
    "        # 验证\n",
    "        if valid_loader: # 如果需要验证\n",
    "            # 验证集指标获取\n",
    "            metric_val_dict = predict_model(model, val_X, val_y, batch_size=batch_size, task=task, metrics=metrics, device=device)\n",
    "            for i in metric_val_dict: metrics_dict[\"val_\"+i] = metric_val_dict[i]\n",
    "            if verbose > 0 and epoch % verbose == 0: print(metrics_dict)\n",
    "            metrics_total.append(metrics_dict) # 记录指标结果\n",
    "            \n",
    "            if eval_metric or save_path:        \n",
    "                val_metric = metrics_dict[\"val_\"+eval_metric] if eval_metric == \"loss\" else -metrics_dict[\"val_\"+eval_metric]\n",
    "                if val_metric < threshold:\n",
    "                    threshold, cnt = val_metric, 0\n",
    "                    if save_path:\n",
    "                        torch.save(model.state_dict(), save_path) # 载入模型参数时：model = Network().load_state_dict(torch.load(path)), Network是该自定义的网络\n",
    "                        print(\"model is saved\")\n",
    "                elif val_metric >= threshold and eval_metric:\n",
    "                    cnt += 1\n",
    "                    if cnt > early_stopping_bounds: \n",
    "                        print(\"EarlyStopping!!!\")\n",
    "                        break\n",
    "    \n",
    "        \n",
    "    # 指标可视化\n",
    "    if is_plt:\n",
    "        metrics_total_dict = defaultdict(list)\n",
    "        for m_dict in metrics_total:\n",
    "            for key in m_dict:\n",
    "                if key != \"epoch\": metrics_total_dict[key].append(m_dict[key])\n",
    "        metrics_total_list = list(metrics_total_dict.values())\n",
    "        metrics_total_names = list(metrics_total_dict.keys())\n",
    "        fig, ax = plt.subplots(len(metrics_total_list)//2, figsize=(15,10))\n",
    "        if not isinstance(ax, np.ndarray): ax = [ax]\n",
    "        for i in range(len(ax)):\n",
    "            train_data, valid_data = metrics_total_list[i], metrics_total_list[i+2 if len(ax) == 2 else -1]\n",
    "            train_name, valid_name = metrics_total_names[i], metrics_total_names[i+2 if len(ax) == 2 else -1]\n",
    "            ax[i].plot(range(1, len(train_data)+1), train_data, label=train_name)\n",
    "            ax[i].plot(range(1, len(valid_data)+1), valid_data, label=valid_name)\n",
    "            ax[i].set_xlabel('epoch')\n",
    "            ax[i].grid(True)\n",
    "            ax[i].legend()\n",
    "\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 获取数据\n",
    "    df = pd.read_csv(\"./dataset/binary_practice_data.csv\")\n",
    "    X, y = df.iloc[:,:-1], df.iloc[:,-1]\n",
    "    fea_names = list(X.columns)\n",
    "    X_np, y_np = np.array(X), np.array(y)\n",
    "    X_tensor, y_tensor = torch.tensor(np.array(X)).float(), torch.tensor(np.array(y)).float().unsqueeze(dim=1)\n",
    "    \n",
    "    # 定义网络\n",
    "    class Net(nn.Module): # 定义网络结构\n",
    "        def __init__(self, dim=10):\n",
    "            super(Net, self).__init__()\n",
    "            self.f = nn.Sequential(nn.Linear(dim, dim), nn.Linear(dim, dim), nn.Linear(dim, dim//2), \\\n",
    "                                   nn.Linear(dim//2, dim//2//2), nn.Linear(dim//2//2, 1))\n",
    "            self.dropout = nn.Dropout(0.2)\n",
    "        def forward(self, x):\n",
    "            return F.sigmoid(self.dropout(self.f(x)))\n",
    "    # 开始训练\n",
    "    model = Net(dim=49) \n",
    "    model1 = train_model(model, X_np, y_np, valid_data=None, valid_split=0.2, batch_size=128, opt_criterion=\"adam\", task=\"binary\", \\\n",
    "                metrics=[\"auc\"], eval_metric=\"auc\", epochs=100, early_stopping_bounds=10, seed=2022, \\\n",
    "                learning_rate=0.01, l2=0.01, shuffle=True, save_path=None, device=\"cpu\", verbose=10, is_plt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fe5f7bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m0.1\u001b[39m,\u001b[38;5;241m0.4\u001b[39m,\u001b[38;5;241m0.7\u001b[39m,\u001b[38;5;241m0.8\u001b[39m]])\n\u001b[0;32m      2\u001b[0m b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\loss.py:1120\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1121\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\functional.py:2824\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2823\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 2824\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[0.1,0.4,0.7,0.8]])\n",
    "b = torch.tensor([1])\n",
    "torch.nn.CrossEntropyLoss()(b,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63822330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load dl_train_module\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import recall_score, roc_auc_score, accuracy_score\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore') # 关闭警告\n",
    "\n",
    "def create_dataloader(X, y, batch_size=1, shuffle=True): # 创建batch迭代器函数\n",
    "    torch_dataset = TensorDataset(X, y) # 创建数据集，必须是tensor类型\n",
    "    loader = DataLoader(dataset=torch_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    return loader\n",
    "\n",
    "\n",
    "def get_loss(task): # 获取损失函数\n",
    "    if task == \"binary\":\n",
    "        criterion = torch.nn.BCELoss() # 注：此损失函数要求：1.每个样本只能有一个概率值，即输出是1 dim的tensor；2.要求标签是float类型\n",
    "    elif task == \"multiclass\":\n",
    "        criterion = torch.nn.CrossEntropyLoss() # 注：此损失函数要求：1.每个样本必须有每个类别的概率，即便是2分类，即输出是2 dim的tensor；2.要求标签是long类型；3.标签是1维数据，内容是0/1/2/......，从0开始的类别索引，不是从1开始，也不是多维onehot。\n",
    "    elif task == \"regression_1\": # 回归类损失函数的标签形状要求和二分类的情况一致\n",
    "        criterion = torch.nn.L1Loss()\n",
    "    elif task == \"regression_2\":\n",
    "        criterion = torch.nn.MSELoss()\n",
    "    else:\n",
    "        raise ValueError(\"Please input correct value!!!\")\n",
    "    return criterion\n",
    "\n",
    "\n",
    "def get_optimizer(params, opt_criterion, learning_rate, l2): # 获取梯度优化器函数\n",
    "    if learning_rate <= 0 or l2 < 0: \n",
    "        raise ValueError(\"Please input correct learning_rate and l2!!!\")\n",
    "    if opt_criterion.lower() == \"adam\":\n",
    "        optimizer = torch.optim.Adam(params, lr=learning_rate, weight_decay=l2)\n",
    "    elif opt_criterion.lower() == \"adagrad\":\n",
    "        optimizer = torch.optim.Adagrad(params, lr=learning_rate, weight_decay=l2)\n",
    "    elif opt_criterion.lower() == \"rmsprop\":\n",
    "        optimizer = torch.optim.RMSprop(params, lr=learning_rate, weight_decay=l2)\n",
    "    elif opt_criterion.lower() == \"sgd\":\n",
    "        optimizer = torch.optim.SGD(params, lr=learning_rate, weight_decay=l2)\n",
    "    else:\n",
    "        raise ValueError(\"Please input correct opt_criterion!!!\")\n",
    "    return optimizer\n",
    "\n",
    "def weight_init(m): # 网络参数初始化函数\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        torch.nn.init.constant_(m.weight, 1)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "\n",
    "def seed_torch(seed=2022): # 固定所有随机种子函数\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) # 为了禁止hash随机化，使得实验可复现\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "\n",
    "# 预测/验证函数\n",
    "def predict_model(model, test_X, test_y = None, batch_size=1, task=None, metrics=None, device=\"cpu\"): # 有test_y时验证，没有时预测\n",
    "    test_loader = create_dataloader(test_X, test_y, batch_size=batch_size, shuffle=False)\n",
    "    loss_func = get_loss(task)\n",
    "    model = model.eval()\n",
    "    pred_ans, loss = [], 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device).float()\n",
    "            target = target.to(device).squeeze() # 真实标签不管什么时候都需要是1dim tensor数据\n",
    "            target = target.long() if task == \"multiclass\" else target.float() # 但数据类型需要灵活，多分类时需要是long，其他时候都是float。\n",
    "            output = model(data).squeeze(dim=-1) # 输出结果一定在最后一个维度处压缩一下，二分类和回归对此有要求，需要1维数据；而多分类输出虽然不是1dim，但它的最后一个维度不是1，所以不会受到这个压缩的影响，不会出错。\n",
    "            pred_ans.append(output.cpu().data.numpy()) # 如果要将tensor类型转为numpy类型，那么该数据必须要存在cpu上才行！\n",
    "            loss += loss_func(output, target).item()\n",
    "    y_pred = np.concatenate(pred_ans).astype(\"float64\")\n",
    "    \n",
    "    if test_y is not None:\n",
    "        metrics_d = {}\n",
    "        for i in metrics:\n",
    "            if \"auc\" in i:\n",
    "                metrics_d[\"auc\"] = roc_auc_score(test_y.squeeze().data.numpy(), y_pred) # roc_auc_score的真实标签必须在前面\n",
    "            elif \"loss\" in i:\n",
    "                metrics_d[\"loss\"] = loss/len(y_pred)\n",
    "        return metrics_d\n",
    "    else:\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "def train_model(model, X, y, valid_data=None, valid_split=0., batch_size=1, opt_criterion=\"adam\", task=\"binary\", \\\n",
    "                metrics=[\"loss\",\"auc\"], eval_metric=\"auc\", epochs=100, early_stopping_bounds=None, seed=2022, \\\n",
    "                learning_rate=0.01, l2=0.01, shuffle=True, save_path=None, device=\"cpu\", verbose=0, is_plt=True):\n",
    "    \n",
    "    # 固定随机数种子\n",
    "    seed_torch(seed=seed)\n",
    "    \n",
    "    # 模型设置\n",
    "    model = model.to(device) # 将参数部署到指定设备\n",
    "    model.apply(weight_init) # 初始化参数\n",
    "    loss_func = get_loss(task) # 获取损失函数\n",
    "    optimizer = get_optimizer(model.parameters(), opt_criterion, learning_rate, l2) # 获取梯度优化器\n",
    "    \n",
    "    # 数据设置\n",
    "    X, y = torch.tensor(X), torch.tensor(y).unsqueeze(dim=1) # 将numpy的输入转为tensor，记得要将标签升维用以切分数据集，后面再降为1dim\n",
    "    if valid_data and len(valid_data) == 2: # 优先自主设置验证集\n",
    "        train_loader = create_dataloader(X, y, batch_size=batch_size, shuffle=shuffle)\n",
    "        val_X, val_y = valid_data[0], valid_data[1]\n",
    "        valid_loader = create_dataloader(val_X, val_y, batch_size=batch_size, shuffle=shuffle)\n",
    "    elif 1 > valid_split > 0: # 从数据中拆分验证集\n",
    "        len_data = list(range(X.shape[0]))\n",
    "        np.random.shuffle(len_data)\n",
    "        train_index, valid_index = len_data[:int((1-valid_split)*X.shape[0])], len_data[int((1-valid_split)*X.shape[0]):] # 获取训练集和验证集各自索引列表\n",
    "        X, val_X, y, val_y = X[train_index], X[valid_index], y[train_index], y[valid_index]\n",
    "        train_loader = create_dataloader(X, y, batch_size=batch_size, shuffle=shuffle)\n",
    "        valid_loader = create_dataloader(val_X, val_y, batch_size=batch_size, shuffle=shuffle)\n",
    "    elif valid_split == 0: # 如果不设置验证集\n",
    "        train_loader = create_dataloader(X, y, batch_size=batch_size, shuffle=shuffle)\n",
    "        valid_loader = None\n",
    "    else:\n",
    "        raise ValueError(\"Please input correct valid_dataset!!!\")\n",
    "\n",
    "    # 训练模型\n",
    "    metrics_total = [] # 所有迭代次数指标结果集合\n",
    "    metrics_dict = {} # 每个epoch指标结果\n",
    "    if eval_metric or save_path: # 如果使用早停或者要保存参数\n",
    "        if eval_metric not in [\"auc\", \"loss\", None]:\n",
    "                raise ValueError(\"Please input correct eval_metric!!!!\")\n",
    "        threshold = float(\"inf\") # 早停阈值（实时更新）\n",
    "        cnt = 0 # 早停计数器\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        metrics_dict[\"epoch\"] = epoch\n",
    "        \n",
    "        # 训练\n",
    "        model = model.train()\n",
    "        for data, target in train_loader:\n",
    "            data = data.to(device).float()\n",
    "            target = target.to(device).squeeze()\n",
    "            target = target.long() if task == \"multiclass\" else target.float()\n",
    "            output = model(data).squeeze(dim=-1) # 如果是二分类或回归，输出必须是1dim，如果是多分类，dim=-1不会改变输出\n",
    "            loss = loss_func(output, target)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=20, norm_type=2) # 梯度裁剪，参数介绍：参数集合；最大梯度范数；梯度范数类型\n",
    "            optimizer.step()\n",
    "            \n",
    "        # 训练集指标获取\n",
    "        metric_train_dict = predict_model(model, X, y, batch_size=batch_size, task=task, metrics=metrics, device=device)\n",
    "        for i in metric_train_dict: metrics_dict[\"train_\"+i] = metric_train_dict[i]\n",
    "        if not valid_loader: \n",
    "            if verbose > 0 and epoch % verbose == 0: print(metrics_dict) # 如果不需要验证直接输出指标结果\n",
    "            metrics_total.append(metrics_dict) # 记录指标结果\n",
    "        \n",
    "        # 验证\n",
    "        if valid_loader: # 如果需要验证\n",
    "            # 验证集指标获取\n",
    "            metric_val_dict = predict_model(model, val_X, val_y, batch_size=batch_size, task=task, metrics=metrics, device=device)\n",
    "            for i in metric_val_dict: metrics_dict[\"val_\"+i] = metric_val_dict[i]\n",
    "            if verbose > 0 and epoch % verbose == 0: print(metrics_dict)\n",
    "            metrics_total.append(metrics_dict) # 记录指标结果\n",
    "            \n",
    "            if eval_metric or save_path:        \n",
    "                val_metric = metrics_dict[\"val_\"+eval_metric] if eval_metric == \"loss\" else -metrics_dict[\"val_\"+eval_metric]\n",
    "                if val_metric < threshold:\n",
    "                    threshold, cnt = val_metric, 0\n",
    "                    if save_path:\n",
    "                        torch.save(model.state_dict(), save_path) # 载入模型参数时：model = Network().load_state_dict(torch.load(path)), Network是该自定义的网络\n",
    "                        print(\"model is saved\")\n",
    "                elif val_metric >= threshold and eval_metric:\n",
    "                    cnt += 1\n",
    "                    if cnt > early_stopping_bounds: \n",
    "                        print(\"EarlyStopping!!!\")\n",
    "                        break\n",
    "    \n",
    "        \n",
    "    # 指标可视化\n",
    "    if is_plt:\n",
    "        metrics_total_dict = defaultdict(list)\n",
    "        for m_dict in metrics_total:\n",
    "            for key in m_dict:\n",
    "                if key != \"epoch\": metrics_total_dict[key].append(m_dict[key])\n",
    "        metrics_total_list = list(metrics_total_dict.values())\n",
    "        metrics_total_names = list(metrics_total_dict.keys())\n",
    "        fig, ax = plt.subplots(len(metrics_total_list)//2, figsize=(15,10))\n",
    "        if not isinstance(ax, np.ndarray): ax = [ax]\n",
    "        for i in range(len(ax)):\n",
    "            train_data, valid_data = metrics_total_list[i], metrics_total_list[i+2 if len(ax) == 2 else -1]\n",
    "            train_name, valid_name = metrics_total_names[i], metrics_total_names[i+2 if len(ax) == 2 else -1]\n",
    "            ax[i].plot(range(1, len(train_data)+1), train_data, label=train_name)\n",
    "            ax[i].plot(range(1, len(valid_data)+1), valid_data, label=valid_name)\n",
    "            ax[i].set_xlabel('epoch')\n",
    "            ax[i].grid(True)\n",
    "            ax[i].legend()\n",
    "\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 获取数据\n",
    "    df = pd.read_csv(\"./dataset/binary_practice_data.csv\")\n",
    "    X, y = df.iloc[:,:-1], df.iloc[:,-1]\n",
    "    fea_names = list(X.columns)\n",
    "    X_np, y_np = np.array(X), np.array(y)\n",
    "    X_tensor, y_tensor = torch.tensor(np.array(X)).float(), torch.tensor(np.array(y)).float().unsqueeze(dim=1)\n",
    "    \n",
    "    # 定义网络\n",
    "    class Net(nn.Module): # 定义网络结构\n",
    "        def __init__(self, dim=10):\n",
    "            super(Net, self).__init__()\n",
    "            self.f = nn.Sequential(nn.Linear(dim, dim), nn.Linear(dim, dim), nn.Linear(dim, dim//2), \\\n",
    "                                   nn.Linear(dim//2, dim//2//2), nn.Linear(dim//2//2, 1))\n",
    "            self.dropout = nn.Dropout(0.2)\n",
    "        def forward(self, x):\n",
    "            return F.sigmoid(self.dropout(self.f(x)))\n",
    "    # 开始训练\n",
    "    model = Net(dim=49) \n",
    "    model1 = train_model(model, X_np, y_np, valid_data=None, valid_split=0.2, batch_size=128, opt_criterion=\"adam\", task=\"binary\", \\\n",
    "                metrics=[\"auc\"], eval_metric=\"auc\", epochs=100, early_stopping_bounds=10, \\\n",
    "                learning_rate=0.01, l2=0.01, shuffle=True, save_path=None, device=\"cpu\", verbose=10, is_plt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a2f508",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
