{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a2b4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import recall_score, roc_auc_score, accuracy_score\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore') # 关闭警告\n",
    "\n",
    "def create_dataloader(X, y, batch_size=1, shuffle=True): # 创建batch迭代器函数\n",
    "    torch_dataset = TensorDataset(X, y)\n",
    "    loader = DataLoader(dataset=torch_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    return loader\n",
    "\n",
    "\n",
    "def get_loss(task): # 获取损失函数\n",
    "    if task == \"binary\":\n",
    "        criterion = torch.nn.BCELoss() # 注：此损失函数要求：1.每个样本只能有一个概率值，即输出是1 dim的tensor；2.要求标签是float类型\n",
    "    elif task == \"multiclass\":\n",
    "        criterion = torch.nn.CrossEntropyLoss() # 注：此损失函数要求：1.每个样本必须有每个类别的概率，即便是2分类，即输出是2 dim的tensor；2.要求标签是long类型\n",
    "    elif task == \"regression_1\":\n",
    "        criterion = torch.nn.L1Loss()\n",
    "    elif task == \"regression_2\":\n",
    "        criterion = torch.nn.MSELoss()\n",
    "    else:\n",
    "        raise ValueError(\"Please input correct value!!!\")\n",
    "    return criterion\n",
    "\n",
    "\n",
    "def get_optimizer(params, opt_criterion, learning_rate, l2): # 获取梯度优化器函数\n",
    "    if learning_rate <= 0 or l2 < 0: \n",
    "        raise ValueError(\"Please input correct learning_rate and l2!!!\")\n",
    "    if opt_criterion.lower() == \"adam\":\n",
    "        optimizer = torch.optim.Adam(params, lr=learning_rate, weight_decay=l2)\n",
    "    elif opt_criterion.lower() == \"adagrad\":\n",
    "        optimizer = torch.optim.Adagrad(params, lr=learning_rate, weight_decay=l2)\n",
    "    elif opt_criterion.lower() == \"rmsprop\":\n",
    "        optimizer = torch.optim.RMSprop(params, lr=learning_rate, weight_decay=l2)\n",
    "    elif opt_criterion.lower() == \"sgd\":\n",
    "        optimizer = torch.optim.SGD(params, lr=learning_rate, weight_decay=l2)\n",
    "    else:\n",
    "        raise ValueError(\"Please input correct opt_criterion!!!\")\n",
    "    return optimizer\n",
    "\n",
    "def weight_init(m): # 网络参数初始化函数\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        torch.nn.init.constant_(m.weight, 1)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "\n",
    "def seed_torch(seed=2022): # 固定所有随机种子函数\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) # 为了禁止hash随机化，使得实验可复现\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "\n",
    "# 预测/验证函数\n",
    "def predict_model(model, test_X, test_y = None, batch_size=1, task=None, metrics=None, device=\"cpu\"): # 有test_y时验证，没有时预测\n",
    "    test_loader = create_dataloader(test_X, test_y, batch_size=batch_size, shuffle=False)\n",
    "    loss_func = get_loss(task)\n",
    "    model = model.eval()\n",
    "    pred_ans, loss = [], 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device).float()\n",
    "            target = target.to(device).float().squeeze()\n",
    "            output = model(data).squeeze(dim=-1)\n",
    "            pred_ans.append(output.cpu().data.numpy())\n",
    "            loss += loss_func(output, target).item()\n",
    "    y_pred = np.concatenate(pred_ans).astype(\"float64\")\n",
    "    \n",
    "    if test_y is not None:\n",
    "        metrics_d = {}\n",
    "        for i in metrics:\n",
    "            if \"auc\" in i:\n",
    "                metrics_d[\"auc\"] = roc_auc_score(test_y.squeeze().data.numpy(), y_pred) # roc_auc_score的真实标签必须在前面\n",
    "            elif \"loss\" in i:\n",
    "                metrics_d[\"loss\"] = loss/len(y_pred)\n",
    "        return metrics_d\n",
    "    else:\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "def train_model(model, X, y, valid_data=None, valid_split=0., batch_size=1, opt_criterion=\"adam\", task=\"binary\", \\\n",
    "                metrics=[\"loss\",\"auc\"], eval_metric=\"auc\", epochs=100, early_stopping_bounds=None, seed=2022, \\\n",
    "                learning_rate=0.01, l2=0.01, shuffle=True, save_path=None, device=\"cpu\", verbose=0, is_plt=True):\n",
    "    \n",
    "    # 固定随机数种子\n",
    "    seed_torch(seed=seed)\n",
    "    \n",
    "    # 模型设置\n",
    "    model = model.to(device) # 将参数部署到指定设备\n",
    "    model.apply(weight_init) # 初始化参数\n",
    "    loss_func = get_loss(task) # 获取损失函数\n",
    "    optimizer = get_optimizer(model.parameters(), opt_criterion, learning_rate, l2) # 获取梯度优化器\n",
    "    \n",
    "    # 数据设置\n",
    "    X, y = torch.tensor(X), torch.tensor(y).unsqueeze(dim=1) # 将numpy的输入转为tensor，记得要将标签升维用以切分数据集，后面再降为1dim\n",
    "    if valid_data and len(valid_data) == 2: # 优先自主设置验证集\n",
    "        train_loader = create_dataloader(X, y, batch_size=batch_size, shuffle=shuffle)\n",
    "        val_X, val_y = valid_data[0], valid_data[1]\n",
    "        valid_loader = create_dataloader(val_X, val_y, batch_size=batch_size, shuffle=shuffle)\n",
    "    elif 1 > valid_split > 0: # 从数据中拆分验证集\n",
    "        len_data = list(range(X.shape[0]))\n",
    "        np.random.shuffle(len_data)\n",
    "        train_index, valid_index = len_data[:int((1-valid_split)*X.shape[0])], len_data[int((1-valid_split)*X.shape[0]):] # 获取训练集和验证集各自索引列表\n",
    "        X, val_X, y, val_y = X[train_index], X[valid_index], y[train_index], y[valid_index]\n",
    "        train_loader = create_dataloader(X, y, batch_size=batch_size, shuffle=shuffle)\n",
    "        valid_loader = create_dataloader(val_X, val_y, batch_size=batch_size, shuffle=shuffle)\n",
    "    elif valid_split == 0: # 如果不设置验证集\n",
    "        train_loader = create_dataloader(X, y, batch_size=batch_size, shuffle=shuffle)\n",
    "        valid_loader = None\n",
    "    else:\n",
    "        raise ValueError(\"Please input correct valid_dataset!!!\")\n",
    "\n",
    "    # 训练模型\n",
    "    metrics_total = [] # 所有迭代次数指标结果集合\n",
    "    metrics_dict = {} # 每个epoch指标结果\n",
    "    if eval_metric or save_path: # 如果使用早停或者要保存参数\n",
    "        if eval_metric not in [\"auc\", \"loss\", None]:\n",
    "                raise ValueError(\"Please input correct eval_metric!!!!\")\n",
    "        threshold = float(\"inf\") # 早停阈值（实时更新）\n",
    "        cnt = 0 # 早停计数器\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        metrics_dict[\"epoch\"] = epoch\n",
    "        \n",
    "        # 训练\n",
    "        model = model.train()\n",
    "        for data, target in train_loader:\n",
    "            data = data.to(device).float()\n",
    "            target = target.to(device).float().squeeze() # 标签后面做运算时候必须是1dim\n",
    "            output = model(data).squeeze(dim=-1) # 如果是二分类或回归，输出必须是1dim，如果是多分类，dim=-1不会改变输出\n",
    "            loss = loss_func(output, target)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10, norm_type=2) # 梯度裁剪，参数介绍：参数集合；最大梯度范数；梯度范数类型\n",
    "            optimizer.step()\n",
    "            \n",
    "        # 训练集指标获取\n",
    "        metric_train_dict = predict_model(model, X, y, batch_size=batch_size, task=task, metrics=metrics, device=device)\n",
    "        for i in metric_train_dict: metrics_dict[\"train_\"+i] = metric_train_dict[i]\n",
    "        if not valid_loader: \n",
    "            if verbose > 0 and epoch % verbose == 0: print(metrics_dict) # 如果不需要验证直接输出指标结果\n",
    "            metrics_total.append(metrics_dict) # 记录指标结果\n",
    "        \n",
    "        # 验证\n",
    "        if valid_loader: # 如果需要验证\n",
    "            # 验证集指标获取\n",
    "            metric_val_dict = predict_model(model, val_X, val_y, batch_size=batch_size, task=task, metrics=metrics, device=device)\n",
    "            for i in metric_val_dict: metrics_dict[\"val_\"+i] = metric_val_dict[i]\n",
    "            if verbose > 0 and epoch % verbose == 0: print(metrics_dict)\n",
    "            metrics_total.append(metrics_dict) # 记录指标结果\n",
    "            \n",
    "            if eval_metric or save_path:        \n",
    "                val_metric = metrics_dict[\"val_\"+eval_metric] if eval_metric == \"loss\" else -metrics_dict[\"val_\"+eval_metric]\n",
    "                if val_metric < threshold:\n",
    "                    threshold, cnt = val_metric, 0\n",
    "                    if save_path:\n",
    "                        torch.save(model.state_dict(), save_path) # 载入模型参数时：model = Network().load_state_dict(torch.load(path)), Network是该自定义的网络\n",
    "                        print(\"model is saved\")\n",
    "                elif val_metric >= threshold and eval_metric:\n",
    "                    cnt += 1\n",
    "                    if cnt > early_stopping_bounds: \n",
    "                        print(\"EarlyStopping!!!\")\n",
    "                        break\n",
    "    \n",
    "        \n",
    "    # 指标可视化\n",
    "    if is_plt:\n",
    "        metrics_total_dict = defaultdict(list)\n",
    "        for m_dict in metrics_total:\n",
    "            for key in m_dict:\n",
    "                if key != \"epoch\": metrics_total_dict[key].append(m_dict[key])\n",
    "        metrics_total_list = list(metrics_total_dict.values())\n",
    "        metrics_total_names = list(metrics_total_dict.keys())\n",
    "        print(metrics_total_names)\n",
    "        fig, ax = plt.subplots(len(metrics_total_list)//2, figsize=(15,10))\n",
    "        if not isinstance(ax, np.ndarray): ax = [ax]\n",
    "        for i in range(len(ax)):\n",
    "            train_data, valid_data = metrics_total_list[i], metrics_total_list[i+2 if len(ax) == 2 else -1]\n",
    "            train_name, valid_name = metrics_total_names[i], metrics_total_names[i+2 if len(ax) == 2 else -1]\n",
    "            ax[i].plot(range(1, len(train_data)+1), train_data, label=train_name)\n",
    "            ax[i].plot(range(1, len(valid_data)+1), valid_data, label=valid_name)\n",
    "            ax[i].set_xlabel('epoch')\n",
    "            ax[i].grid(True)\n",
    "            ax[i].legend()\n",
    "\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 获取数据\n",
    "    df = pd.read_csv(\"./dataset/binary_practice_data.csv\")\n",
    "    X, y = df.iloc[:,:-1], df.iloc[:,-1]\n",
    "    fea_names = list(X.columns)\n",
    "    X_np, y_np = np.array(X), np.array(y)\n",
    "    X_tensor, y_tensor = torch.tensor(np.array(X)).float(), torch.tensor(np.array(y)).float().unsqueeze(dim=1)\n",
    "    \n",
    "    # 定义网络\n",
    "    class Net(nn.Module): # 定义网络结构\n",
    "        def __init__(self, dim=10):\n",
    "            super(Net, self).__init__()\n",
    "            self.f = nn.Sequential(nn.Linear(dim, dim), nn.Linear(dim, dim), nn.Linear(dim, dim//2), \\\n",
    "                                   nn.Linear(dim//2, dim//2//2), nn.Linear(dim//2//2, 1))\n",
    "            self.dropout = nn.Dropout(0.2)\n",
    "        def forward(self, x):\n",
    "            return F.sigmoid(self.dropout(self.f(x)))\n",
    "    # 开始训练\n",
    "    model = Net(dim=49) \n",
    "    model1 = train_model(model, X_np, y_np, valid_data=None, valid_split=0.2, batch_size=128, opt_criterion=\"adam\", task=\"binary\", \\\n",
    "                metrics=[\"auc\"], eval_metric=\"auc\", epochs=100, early_stopping_bounds=10, seed=2022, \\\n",
    "                learning_rate=0.01, l2=0.01, shuffle=True, save_path=None, device=\"cuda\", verbose=10, is_plt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "3fe5f7bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
