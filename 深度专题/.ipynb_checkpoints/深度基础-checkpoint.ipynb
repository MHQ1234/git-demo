{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 动手深度学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorch基础"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 6, 7]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义张量（数组）\n",
    "x = torch.tensor([[1,2,3], [4,6,7]], dtype = torch.float32) # 相当于np.array()，极其相似，但是类型不同\n",
    "x = torch.arange(12) # 跟np.arange()效果相同\n",
    "torch.zeros(3,4) # 定义指定形状的数组，类似的numpy操作都可实现\n",
    "# tensor的四则运算规则同数组的也是相同的性质\n",
    "# 0维度张量，专门0维度张量的原因是：GPU中不能运行普通的1等标量，只能识别tensor(1)这种0维度张量\n",
    "torch.tensor([1]) # 1维张量\n",
    "torch.tensor(1) # 0维张量，也就是标量\n",
    "# 高维张量：类似于高维numpy数组，不做具体介绍\n",
    "\n",
    "\n",
    "# 查看张量信息\n",
    "x.ndim # 返回维度数（有几个维度）\n",
    "x.shape # 返回形状（每个层维度的个数组合）\n",
    "len(x) # 返回张量多个维度中最高层级维度的个数\n",
    "x.numel() # 最底层元素总数量\n",
    "x.dtype # 查看张量数据类型\n",
    "\n",
    "\n",
    "# 张量的形变\n",
    "x = torch.tensor([[1,2,3,4],[5,6,7,8],[9,9,9,9]])\n",
    "x.flatten() # 将任意维度张量拉伸为1维张量，包括0维张量\n",
    "x.reshape(3, 4) # 改变张量为指定形状，跟np.reshape相同\n",
    "x.reshape(12) # 变为1维张量，或者写作x.reshape(12,)，但是x.shape(12,1)是二维张量\n",
    "# reshape的参数输入对应于.shape的结果，他们的意思是一样的\n",
    "\n",
    "\n",
    "# 张量的索引\n",
    "# 1. 与数组的索引相同，但要注意的是，索引找到的最基本的元素都是0维张量，不是基本的标量，比如索引结果是tensor(1),而不是1\n",
    "# 2. 切片操作基本与numpy数组的索引相同，但有点区别，如下举例\n",
    "x[1:8:2] # 从第2个元素到第8个元素隔2步索引一次\n",
    "x[1::2] # 从第2个到尾，隔2步索引一次\n",
    "x[::2] # 从头到尾，balabala\n",
    "# 3. x[8:1:-2] 这种操作不行，torch不支持倒着索引\n",
    "# 4. 高维张量索引，与numpy的也没什么\n",
    "# 5. index_select(,,)索引：本质上任何索引都可以x[,,,...]解决，但是当维度很高的时候，有些操作会很麻烦。\n",
    "# 比如我想对一个有100个维度的张量做操作：取出第50个维中的前两行，正常写法是x[:,:,:...,[0,1],:,:,...],过于麻烦，但使用index_select就很方便\n",
    "# torch.index_select用于取出某一个特定维度的某几个列数据\n",
    "x = torch.arange(24).reshape(2,3,4)\n",
    "torch.index_select(x, 2, torch.tensor(0)) # 用法：x是目标张量，第二个参数是第几个维度，第三个参数是索引值，可以是多个，但必须是tensor型，不能是列表或数组型\n",
    "torch.index_select(x, 1, torch.tensor([0])) # 只索引一个单位时，可以用0维或者1维张量\n",
    "torch.index_select(x, 0, torch.tensor([0,1])) # 索引多个单位\n",
    "# 注：torch.tensor([0:1])是不对的！，不能写成切片，第三个参数本质是一个tensor类型的数据！\n",
    "\n",
    "\n",
    "# 张量的切分\n",
    "# 1. view()方法，张量的视图\n",
    "x = torch.arange(12).reshape(3,4)\n",
    "y = x.view(4,3) # 此处view的作用类似于reshape。看上去y和x是不同的对象，但其实指向同一个存储空间，x和y可以看做一个数据的不同表现形式，改变x后Y也会改变，但仍然是不同形状\n",
    "\n",
    "# 2. torch.chunk(t, 4, dim = 0)方法：将张量进行切分的函数。t是要被切分的张量，4是等切分成4份，dim是从哪个维度上切，0是默认最高维，以此类推\n",
    "x = torch.arange(12).reshape(3,4)\n",
    "y = torch.chunk(x, 4, dim = 1) # y是将x按列切分四等份的结果\n",
    "# 注：关于输出结果：是一个元组，其元素是切分后的各个单位；切分后的个体也是tensor对象；切分后每个个体仍然保持没切分的维度，不会降维；\n",
    "# 返回的结果也是视图，不是新对象；默认是等分，但如果不能等分也不会报错，会寻找近似等分，或者不等分\n",
    "\n",
    "# 3. torch.split(t, [a1,a2,a3...], dim = ) 与chunk相似，但有区别，第二个参数可以输入一个列表，表示自定义切分分配方案，要求总和等于对应维度的分量个数\n",
    "x = torch.arange(12).reshape(3,4)\n",
    "y = torch.split(x, 4, dim = 1) # 此时的split与chunk效果相同\n",
    "z = torch.split(x, [1,1,2], dim = 1) # 按照列进行1、1、2份数分配方案的切分\n",
    "\n",
    "\n",
    "# 张量的合并\n",
    "# 1. torch.cat([x,y], dim = 1)，张量拼接操作，类似于numpy的vstack和hstack，以及pandas的concat；dim是选择按哪个维度拼接，默认是0\n",
    "x = torch.zeros((4,4))\n",
    "y = torch.zeros((4,4))\n",
    "torch.cat([x,y], dim = 1) # 按列拼接（横着拼）\n",
    "\n",
    "# 2. torch.stack([x,y]) 张量堆叠函数，并不是拼接，而是把相同形状的多个张量堆到一起，整体升高一个维度（类似于list的append）\n",
    "# 注：x和y的shape必须完全相同才行，否则会报错\n",
    "\n",
    "\n",
    "# 张量的广播\n",
    "# 1. 相同维度相同形状的两个张量广播，对应位置进行计算即可\n",
    "# 2. 相同维度不同形状的两个张量广播，要求在导致形状不同的每个维度上，两个张量中至少有一个在该维度的分量数只有1才行\n",
    "# 3. 不同维度的两个张量广播，低纬度的张量先升维到与高纬度张量相同维度，然后再按照同纬度张量广播规则判定即可\n",
    "# 不同维度广播运算举例：x.shape = (2,1)， y.shape = (3,2,4)。x根据情况选择升维成(1,2,1)，然后(1,2,1)与(3,2,4)是课广播的\n",
    "\n",
    "\n",
    "# 基本并行运算（axis与dim都可以使用，效果相同)\n",
    "x = torch.arange(12).reshape(3,4)\n",
    "x.sum() # 对所有元素求和\n",
    "x.sum(dim = 0) # 对所有行求和，返回长度为3的向量\n",
    "x.sum(dim = 1) # 对所有列求和，返回长度为4的向量\n",
    "x,sum(dim = [0, 1]) # 对于多维数组，对其中某几维进行求和，这里只有2维所以结果跟sum()一样\n",
    "# 排序运算\n",
    "x = torch.randn(12).reshape(3,4) \n",
    "y = x.sort(dim = 1, descending = False).values # 将x按照某个维度升序（默认）排序，这个维度的每个分量都会独立进行排序（打乱对应关系），默认是0；返回的内容比较复杂，.values后是值\n",
    "\n",
    "\n",
    "\n",
    "# 矩阵的基本运算\n",
    "t1 = torch.arange(1,7).reshape(2,3).float()\n",
    "t2 = torch.arange(1,10).reshape(3,3).float()\n",
    "t = torch.arange(3).float()\n",
    "torch.t(t1) # 矩阵转置 \n",
    "torch.eye(3) # 单位阵创建\n",
    "torch.diag(t1.reshape(6)) # 将1维张量变成对角阵元素\n",
    "torch.dot(t,t) # 向量内积运算，dot只支持向量运算\n",
    "torch.mm(t1,t2) # 矩阵乘法，t1 * t2是对应元素相乘\n",
    "torch.mv(t1,t) ### 注意：特殊的矩阵与向量相乘的方法，并非是矩阵运算，而是把矩阵的每行当成一个向量分别与某个向量进行内积，返回各自内积结果组成的1维向量\n",
    "torch.mv(t2, t.reshape(3,1)) # 会报错，不能竖着来\n",
    "torch.mm(t1, t.reshape(3,1)) # 作为矩阵运算可以\n",
    "\n",
    "# 矩阵线性代数运算（不举例了，懒）\n",
    "torch.trace() # 矩阵的迹\n",
    "torch.matrix_rank() # 矩阵的秩\n",
    "torch.det() # 矩阵行列式计算\n",
    "torch.inverse() # 矩阵求逆\n",
    "torch.lstsq(y, X) # 最小二乘结果，y是因变量，X是带1列向量的变量矩阵\n",
    "torch.linalg.norm(t) # 求张量内所有元素平方和开根号（必须是float类型）\n",
    "torch.linalg.norm(t,1) # 求张量内所有元素绝对值和（必须是float类型）\n",
    "\n",
    "\n",
    "\n",
    "# 微分运算\n",
    "a = torch.tensor(1., requires_grad = True) # 创建一个张量的时候可以设置这个张量是否可以进行微分运算，默认是False（必须针对浮点型）\n",
    "b = torch.tensor(1., requires_grad = True)\n",
    "a.requires_grad # 用于查看这个张量是否可以微分\n",
    "# a.requires_grad = False # 可以设置为False\n",
    "sse = torch.pow((2-a-b),2) + torch.pow((4-3*a-b),2)\n",
    "torch.autograd.grad(sse, [a, b]) # 这个是对sse这个函数进行偏导运算，a和b就是变量，但是要先赋值，然后返回的是sse在a和b两个方向的导数在他们各自取值下的导数值\n",
    "\n",
    "x = torch.tensor(1., requires_grad = True)\n",
    "y = x ** 2\n",
    "y.retain_grad() # 加上这个后，z对x进行求导时候也能顺带保存z对y求导的中间结果，没有这句，不能y.grad\n",
    "z = y ** 2\n",
    "y.requires_grad # True\n",
    "z.requires_grad # True\n",
    "z.backward() # 反向传播，就是z对最底层的x求导，结果再代入x的值的最终结果，这个本身不返回什么\n",
    "x.grad # 紧接着可以这样来查看刚才计算的结果，这个是用来看x的求导结果的\n",
    "y.grad # 作为中间变量的y，在z对x求导的过程中，只有在y.retain_grad()被设置才可以\n",
    "# y.backward() # y也是可以对x求梯度的\n",
    "# 切记，一个计算图只能backward一次，比如z.backward()之后，就不能再y.backward()了，如下：\n",
    "x = torch.arange(4., requires_grad = True)\n",
    "y = torch.dot(x, x)\n",
    "z = y ** 2 # xyz属于一个计算图\n",
    "y.backward() # y先进行梯度下降\n",
    "print(x.grad) \n",
    "z.backward() # 这时候会报错，因为这个计算图已经计算过梯度了\n",
    "\n",
    "# 改成下面这样可避免问题\n",
    "x = torch.arange(4., requires_grad = True)\n",
    "y = torch.dot(x, x)\n",
    "z = x.sum() # xy和xz属于两个不同的计算图\n",
    "y.backward() # y先进行梯度下降\n",
    "print(x.grad) \n",
    "z.backward() # 正常计算\n",
    "\n",
    "# 继续引出手动梯度清零：上面结果中的第二个x.grad的输出值不是z对x求导代入后的值，而是这个值加上了之前y对x求导得到的值，x梯度会默认累加\n",
    "x.grad.zero_() # 将过往累加的梯度清零，重新开始"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 深度模型训练/预测流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'train_test_model' was not found in history, as a file, url, nor in the user namespace.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3680\u001b[0m, in \u001b[0;36mInteractiveShell.find_user_code\u001b[1;34m(self, target, raw, py_only, skip_encoding_cookie, search_ns)\u001b[0m\n\u001b[0;32m   3679\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:                                              \u001b[38;5;66;03m# User namespace\u001b[39;00m\n\u001b[1;32m-> 3680\u001b[0m     codeobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_ns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m<string>:1\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_model' is not defined",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mload\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_test_model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2285\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2283\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[0;32m   2284\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m-> 2285\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\code.py:359\u001b[0m, in \u001b[0;36mCodeMagics.load\u001b[1;34m(self, arg_s)\u001b[0m\n\u001b[0;32m    357\u001b[0m opts,args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_options(arg_s,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myns:r:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    358\u001b[0m search_ns \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m opts\n\u001b[1;32m--> 359\u001b[0m contents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_user_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_ns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_ns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m opts:\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3682\u001b[0m, in \u001b[0;36mInteractiveShell.find_user_code\u001b[1;34m(self, target, raw, py_only, skip_encoding_cookie, search_ns)\u001b[0m\n\u001b[0;32m   3680\u001b[0m     codeobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns)\n\u001b[0;32m   3681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 3682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m was not found in history, as a file, url, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3683\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnor in the user namespace.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m%\u001b[39m target) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   3685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(codeobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   3686\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m codeobj\n",
      "\u001b[1;31mValueError\u001b[0m: 'train_test_model' was not found in history, as a file, url, nor in the user namespace."
     ]
    }
   ],
   "source": [
    "%load train_test_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 学习实践"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一些注意的点，下面代码暂时没有涉及：\n",
    "1.训练时每次epoch都要使用mini-batch数据\n",
    "2.注意每次输入和输出的shape以及对应的数据类型\n",
    "3.每个epoch后分别记录一次训练集和验证集的loss和ACC、AUC等评分指标，并最终画图展示以观察拟合情况（过拟合or欠拟合）\n",
    "4.由于模型涉及随机初始化和随机GD，相同模型和数据重复结果未必相同，所以要重复执行整个流程多次，叠加多个图＆平均多个结果。\n",
    "5.LSTM很容易过拟合，dropout是必要的步骤，可以在embedding后和LSTM层后都加入\n",
    "6.模型的复杂度要和数据量相适应！\n",
    "7.批量归一化也是比较重要的\n",
    "8.设置早停\n",
    "更多内容见：https://blog.csdn.net/fu_jian_ping/article/details/109147133?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522164423947516781683998851%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=164423947516781683998851&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-109147133.first_rank_v2_pc_rank_v29&utm_term=LSTM%E5%8F%82%E6%95%B0%E8%B0%83%E6%95%B4&spm=1018.2226.3001.4187"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hidden_inital' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-27a2a982e487>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0miter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_final\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 跑模型，得到每个时点的预测结果\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m     \u001b[0mhidden_final\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 计算损失函数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-27a2a982e487>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# hidden_inital是初始存储状态，可不写，那样默认全是0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_final\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_inital\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 返回值：第一个是每个时点的输出值，shape是[batch,sep,output_size];第二个是每个最后一个时点的所有隐层的存储状态，shape是[batch_size,layer_size,hidden_size]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 套输出层\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 把输出结果降维\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hidden_inital' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, optim\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "num_time_steps = 50\n",
    "start = np.random.randint(3, size = 1)[0]\n",
    "time_steps = np.linspace(start, start + 10, num_time_steps)\n",
    "data = np.sin(time_steps).reshape(num_time_steps, 1)\n",
    "x = torch.tensor(data[:-1]).float().view(1, num_time_steps-1, 1)\n",
    "y = torch.tensor(data[1:]).float().view(1, num_time_steps-1, 1)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size): # 参数设置别忘了（这些参数不会默认传给forward函数）\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size = input_size, # 特征维度\n",
    "            hidden_size = hidden_size, # 隐层神经元数\n",
    "            num_layers = num_layers, # 隐层数\n",
    "            batch_first = True # 是否让batch参数总是在第一位\n",
    "        )\n",
    "        self.linear = nn.Linear(hidden_size, output_size) # 输出线性层，如果是分类问题这里的output_size应该是类别数，且要再下面加一层softmax\n",
    "        \n",
    "    def forward(self, x, hidden_inital): # hidden_inital是初始存储状态，可不写，那样默认全是0\n",
    "        out, hidden_final = self.rnn(x, hidden_inital) # 返回值：第一个是每个时点的输出值，shape是[batch,sep,output_size];第二个是每个最后一个时点的所有隐层的存储状态，shape是[batch_size,layer_size,hidden_size]\n",
    "        out = self.linear(out) # 套输出层\n",
    "        out = out.unsqueeze(dim = 0) # 把输出结果降维\n",
    "        return out, hidden_final\n",
    "\n",
    "def xavier(m): # 参数Xavier初始化\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        \n",
    "model = Net(1, 20, 1, 1) # 创建网络（别忘了输入参数）\n",
    "model.apply(xavier) # 应用初始化参数\n",
    "criterion = nn.MSELoss() # 损失函数\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.03) # 梯度优化器\n",
    "hidden_inital = torch.zeros(1, 1, 20) # 初始隐层状态设置（非必须项）\n",
    "\n",
    "epoch = 6\n",
    "for iter in range(epoch):\n",
    "    output, hidden_final = model(x, hidden_inital) # 跑模型，得到每个时点的预测结果\n",
    "    hidden_final = hidden_final.detach()\n",
    "    loss = criterion(output, y) # 计算损失函数\n",
    "    optimizer.zero_grad() # 清零过往参数的梯度结果\n",
    "    loss.backward() # 根据损失函数值计算梯度\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=20, norm_type=2) # 梯度裁剪，参数介绍：参数集合；最大梯度范数；梯度范数类型\n",
    "    optimizer.step() # 根据梯度更新参数\n",
    "    if iter % 100 == 0: print(\"Iteration: {} loss {}\".format(iter, loss.item())) # 每100次迭代返回一次结果\n",
    "\n",
    "pred = [] # 每个时点的预测结果\n",
    "test_x = x[:, 0, :]\n",
    "for i in range(x.shape[1]):\n",
    "    test_x = test_x.view(1,1,1)\n",
    "    pre, h = model(test_x, hidden_inital)\n",
    "    test_x = pre\n",
    "    pred.append(pre.squeeze().detach())\n",
    "x = x.data.numpy().ravel()\n",
    "y = y.data.numpy()\n",
    "plt.scatter(time_steps[:-1], x.squeeze())\n",
    "plt.plot(time_steps[:-1], x.ravel())\n",
    "plt.scatter(time_steps[:-1], pred)\n",
    "plt.show()\n",
    "\n",
    "# 模型存储\n",
    "# torch.save(model.state_dict(), \"simple_net\") # 存储训练好的模型参数\n",
    "# model1 = Net() # 加载的时候自行写模型\n",
    "# model1.load_state_dict(torch.load(\"simple_net\")) # 加载模型参数\n",
    "# model1.eval() # 固定非参数层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size,vocab_size. embedding_dim): # 参数设置别忘了（这些参数不会默认传给forward函数）\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size. embedding_dim)\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size = input_size, # 特征维度\n",
    "            hidden_size = hidden_size, # 隐层神经元数\n",
    "            num_layers = num_layers, # 隐层数\n",
    "            batch_first = True # 是否让batch参数总是在第一位\n",
    "        )\n",
    "        self.linear = nn.Linear(hidden_size, output_size) # 输出线性层，如果是分类问题这里的output_size应该是类别数，且要再下面加一层softmax\n",
    "        \n",
    "    def forward(self, x, hidden_inital): # hidden_inital是初始存储状态，可不写，那样默认全是0\n",
    "        out, hidden_final = self.rnn(x, hidden_inital) # 返回值：第一个是每个时点的输出值，shape是[batch,sep,output_size];第二个是每个最后一个时点的所有隐层的存储状态，shape是[batch_size,layer_size,hidden_size]\n",
    "        out = self.linear(out) # 套输出层\n",
    "        out = out.unsqueeze(dim = 0) # 把输出结果降维\n",
    "        return out, hidden_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer源码(仅供参考）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "写框架的时候两个要点：\n",
    "- 先写大框架，再写小框架，一级一级往下写\n",
    "- 不确定的输入形式可以先不写，后面补上\n",
    "- 时刻清楚数据在每个部分流转时候的形态和类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 2.280869\n",
      "Epoch: 0002 cost = 3.970184\n",
      "Epoch: 0003 cost = 2.795365\n",
      "Epoch: 0004 cost = 5.159268\n",
      "Epoch: 0005 cost = 3.878076\n",
      "Epoch: 0006 cost = 5.810416\n",
      "Epoch: 0007 cost = 5.532382\n",
      "Epoch: 0008 cost = 4.226982\n",
      "Epoch: 0009 cost = 5.170188\n",
      "Epoch: 0010 cost = 1.904359\n",
      "Epoch: 0011 cost = 2.123083\n",
      "Epoch: 0012 cost = 2.040266\n",
      "Epoch: 0013 cost = 2.028134\n",
      "Epoch: 0014 cost = 2.044340\n",
      "Epoch: 0015 cost = 1.865151\n",
      "Epoch: 0016 cost = 1.688594\n",
      "Epoch: 0017 cost = 1.676789\n",
      "Epoch: 0018 cost = 1.732380\n",
      "Epoch: 0019 cost = 1.743735\n",
      "Epoch: 0020 cost = 1.714740\n",
      "ich mochte ein bier P -> ['E', 'E', 'E', 'E', 'E']\n",
      "first head of last state enc_self_attns\n"
     ]
    }
   ],
   "source": [
    "# code by Tae Hwan Jung(Jeff Jung) @graykode, Derek Miller @dmmiller612\n",
    "# Reference : https://github.com/jadore801120/attention-is-all-you-need-pytorch\n",
    "#           https://github.com/JayParks/transformer\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# S: Symbol that shows starting of decoding input\n",
    "# E: Symbol that shows starting of decoding output\n",
    "# P: Symbol that will fill in blank sequence if current batch data size is short than time steps\n",
    "\n",
    "def make_batch(sentences):\n",
    "    input_batch = [[src_vocab[n] for n in sentences[0].split()]]\n",
    "    output_batch = [[tgt_vocab[n] for n in sentences[1].split()]]\n",
    "    target_batch = [[tgt_vocab[n] for n in sentences[2].split()]]\n",
    "    return torch.LongTensor(input_batch), torch.LongTensor(output_batch), torch.LongTensor(target_batch)\n",
    "\n",
    "def get_sinusoid_encoding_table(n_position, d_model):\n",
    "    def cal_angle(position, hid_idx):\n",
    "        return position / np.power(10000, 2 * (hid_idx // 2) / d_model)\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, hid_j) for hid_j in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(n_position)])\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # dim 2i\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # dim 2i+1\n",
    "    return torch.FloatTensor(sinusoid_table)\n",
    "\n",
    "def get_attn_pad_mask(seq_q, seq_k):\n",
    "    batch_size, len_q = seq_q.size()\n",
    "    batch_size, len_k = seq_k.size()\n",
    "    # eq(zero) is PAD token\n",
    "    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)  # batch_size x 1 x len_k(=len_q), one is masking\n",
    "    return pad_attn_mask.expand(batch_size, len_q, len_k)  # batch_size x len_q x len_k\n",
    "\n",
    "def get_attn_subsequent_mask(seq):\n",
    "    attn_shape = [seq.size(0), seq.size(1), seq.size(1)]\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1)\n",
    "    subsequent_mask = torch.from_numpy(subsequent_mask).byte()\n",
    "    return subsequent_mask\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k) # scores : [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
    "        scores.masked_fill_(attn_mask, -1e9) # Fills elements of self tensor with value where mask is one.\n",
    "        attn = nn.Softmax(dim=-1)(scores)\n",
    "        context = torch.matmul(attn, V)\n",
    "        return context, attn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads)\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads)\n",
    "        self.W_V = nn.Linear(d_model, d_v * n_heads)\n",
    "        self.linear = nn.Linear(n_heads * d_v, d_model)\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        # q: [batch_size x len_q x d_model], k: [batch_size x len_k x d_model], v: [batch_size x len_k x d_model]\n",
    "        residual, batch_size = Q, Q.size(0)\n",
    "        # (B, S, D) -proj-> (B, S, D) -split-> (B, S, H, W) -trans-> (B, H, S, W)\n",
    "        q_s = self.W_Q(Q).view(batch_size, -1, n_heads, d_k).transpose(1,2)  # q_s: [batch_size x n_heads x len_q x d_k]\n",
    "        k_s = self.W_K(K).view(batch_size, -1, n_heads, d_k).transpose(1,2)  # k_s: [batch_size x n_heads x len_k x d_k]\n",
    "        v_s = self.W_V(V).view(batch_size, -1, n_heads, d_v).transpose(1,2)  # v_s: [batch_size x n_heads x len_k x d_v]\n",
    "\n",
    "        attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1) # attn_mask : [batch_size x n_heads x len_q x len_k]\n",
    "\n",
    "        # context: [batch_size x n_heads x len_q x d_v], attn: [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
    "        context, attn = ScaledDotProductAttention()(q_s, k_s, v_s, attn_mask)\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, n_heads * d_v) # context: [batch_size x len_q x n_heads * d_v]\n",
    "        output = self.linear(context)\n",
    "        return self.layer_norm(output + residual), attn # output: [batch_size x len_q x d_model]\n",
    "\n",
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        residual = inputs # inputs : [batch_size, len_q, d_model]\n",
    "        output = nn.ReLU()(self.conv1(inputs.transpose(1, 2)))\n",
    "        output = self.conv2(output).transpose(1, 2)\n",
    "        return self.layer_norm(output + residual)\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.enc_self_attn = MultiHeadAttention()\n",
    "        self.pos_ffn = PoswiseFeedForwardNet()\n",
    "\n",
    "    def forward(self, enc_inputs, enc_self_attn_mask):\n",
    "        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask) # enc_inputs to same Q,K,V\n",
    "        enc_outputs = self.pos_ffn(enc_outputs) # enc_outputs: [batch_size x len_q x d_model]\n",
    "        return enc_outputs, attn\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.dec_self_attn = MultiHeadAttention()\n",
    "        self.dec_enc_attn = MultiHeadAttention()\n",
    "        self.pos_ffn = PoswiseFeedForwardNet()\n",
    "\n",
    "    def forward(self, dec_inputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask):\n",
    "        dec_outputs, dec_self_attn = self.dec_self_attn(dec_inputs, dec_inputs, dec_inputs, dec_self_attn_mask)\n",
    "        dec_outputs, dec_enc_attn = self.dec_enc_attn(dec_outputs, enc_outputs, enc_outputs, dec_enc_attn_mask)\n",
    "        dec_outputs = self.pos_ffn(dec_outputs)\n",
    "        return dec_outputs, dec_self_attn, dec_enc_attn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.src_emb = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.pos_emb = nn.Embedding.from_pretrained(get_sinusoid_encoding_table(src_len+1, d_model),freeze=True)\n",
    "        self.layers = nn.ModuleList([EncoderLayer() for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, enc_inputs): # enc_inputs : [batch_size x source_len]\n",
    "        enc_outputs = self.src_emb(enc_inputs) + self.pos_emb(torch.LongTensor([[1,2,3,4,0]]))\n",
    "        enc_self_attn_mask = get_attn_pad_mask(enc_inputs, enc_inputs)\n",
    "        enc_self_attns = []\n",
    "        for layer in self.layers:\n",
    "            enc_outputs, enc_self_attn = layer(enc_outputs, enc_self_attn_mask)\n",
    "            enc_self_attns.append(enc_self_attn)\n",
    "        return enc_outputs, enc_self_attns\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.tgt_emb = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.pos_emb = nn.Embedding.from_pretrained(get_sinusoid_encoding_table(tgt_len+1, d_model),freeze=True)\n",
    "        self.layers = nn.ModuleList([DecoderLayer() for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, dec_inputs, enc_inputs, enc_outputs): # dec_inputs : [batch_size x target_len]\n",
    "        dec_outputs = self.tgt_emb(dec_inputs) + self.pos_emb(torch.LongTensor([[5,1,2,3,4]]))\n",
    "        dec_self_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs)\n",
    "        dec_self_attn_subsequent_mask = get_attn_subsequent_mask(dec_inputs)\n",
    "        dec_self_attn_mask = torch.gt((dec_self_attn_pad_mask + dec_self_attn_subsequent_mask), 0)\n",
    "\n",
    "        dec_enc_attn_mask = get_attn_pad_mask(dec_inputs, enc_inputs)\n",
    "\n",
    "        dec_self_attns, dec_enc_attns = [], []\n",
    "        for layer in self.layers:\n",
    "            dec_outputs, dec_self_attn, dec_enc_attn = layer(dec_outputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask)\n",
    "            dec_self_attns.append(dec_self_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "        return dec_outputs, dec_self_attns, dec_enc_attns\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = Encoder() # 定义encoder类\n",
    "        self.decoder = Decoder() # 定义Decoder类\n",
    "        self.projection = nn.Linear(d_model, tgt_vocab_size, bias=False) # \n",
    "    def forward(self, enc_inputs, dec_inputs):\n",
    "        enc_outputs, enc_self_attns = self.encoder(enc_inputs)\n",
    "        dec_outputs, dec_self_attns, dec_enc_attns = self.decoder(dec_inputs, enc_inputs, enc_outputs)\n",
    "        dec_logits = self.projection(dec_outputs) # dec_logits : [batch_size x src_vocab_size x tgt_vocab_size]\n",
    "        return dec_logits.view(-1, dec_logits.size(-1)), enc_self_attns, dec_self_attns, dec_enc_attns\n",
    "\n",
    "def showgraph(attn):\n",
    "    attn = attn[-1].squeeze(0)[0]\n",
    "    attn = attn.squeeze(0).data.numpy()\n",
    "    fig = plt.figure(figsize=(n_heads, n_heads)) # [n_heads, n_heads]\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attn, cmap='viridis')\n",
    "    ax.set_xticklabels(['']+sentences[0].split(), fontdict={'fontsize': 14}, rotation=90)\n",
    "    ax.set_yticklabels(['']+sentences[2].split(), fontdict={'fontsize': 14})\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__': # 框架搭建完毕，开始使用\n",
    "    # 数据集，只有一个样本，包含编码器输入，解码器输入和真实标签三部分\n",
    "    sentences = ['ich mochte ein bier P', 'S i want a beer', 'i want a beer E'] # P是填充字符；S是开始字符；E是结束字符\n",
    "    src_vocab = {'P': 0, 'ich': 1, 'mochte': 2, 'ein': 3, 'bier': 4} # 编码端字典\n",
    "    src_vocab_size = len(src_vocab) # 字典长度\n",
    "\n",
    "    tgt_vocab = {'P': 0, 'i': 1, 'want': 2, 'a': 3, 'beer': 4, 'S': 5, 'E': 6} # 解码端字典，一般与编码端是一样的\n",
    "#     number_dict = {i: w for i, w in enumerate(tgt_vocab)}\n",
    "    tgt_vocab_size = len(tgt_vocab) # 解码端字典长度\n",
    "\n",
    "    src_len = 5 # length of source # 编码端输入句子长度\n",
    "    tgt_len = 5 # length of target # 解码端输入句子长度\n",
    "\n",
    "    d_model = 512  # Embedding Size # 输入向量经过embedding层后输入的维度\n",
    "    d_ff = 2048  # FeedForward dimension # 全连接层的维度\n",
    "    d_k = d_v = 64  # dimension of K(=Q), V # 输入转化为query,key,value向量的维度\n",
    "    n_layers = 6  # number of Encoder of Decoder Layer # 编码和解码器中block的数量\n",
    "    n_heads = 8  # number of heads in Multi-Head Attention # 多头注意力机制的数量\n",
    "\n",
    "    model = Transformer() # 定义transformer层\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss() # 定义损失函数\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001) # 定义迭代优化器\n",
    "\n",
    "    # 数据处理，将文本型数据进行分词，并转为在字典中对应的索引，这里由于只有一个样本，就没使用迭代器\n",
    "    enc_inputs, dec_inputs, target_batch = make_batch(sentences) # 输出三个部分，分别是编码器、解码器和标签的索引LongTenor列表\n",
    "\n",
    "    for epoch in range(20): # 开始迭代\n",
    "        optimizer.zero_grad() # 参数梯度清零\n",
    "        outputs, enc_self_attns, dec_self_attns, dec_enc_attns = model(enc_inputs, dec_inputs) # 输入输出\n",
    "        loss = criterion(outputs, target_batch.contiguous().view(-1)) # 计算损失函数\n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss)) # 打印迭代结果\n",
    "        loss.backward() # 反向传播\n",
    "        optimizer.step() # 更新参数\n",
    "\n",
    "    # Test\n",
    "    predict, _, _, _ = model(enc_inputs, dec_inputs)\n",
    "    predict = predict.data.max(1, keepdim=True)[1]\n",
    "    print(sentences[0], '->', [number_dict[n.item()] for n in predict.squeeze()])\n",
    "\n",
    "    print('first head of last state enc_self_attns')\n",
    "    showgraph(enc_self_attns)\n",
    "\n",
    "    print('first head of last state dec_self_attns')\n",
    "    showgraph(dec_self_attns)\n",
    "\n",
    "    print('first head of last state dec_enc_attns')\n",
    "    showgraph(dec_enc_attns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文本数据预处理过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 使用gensim处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts: [['human', 'machine', 'interface', 'lab', 'abc', 'computer', 'applications'], ['survey', 'user', 'opinion', 'computer', 'system', 'response', 'time'], ['eps', 'user', 'interface', 'management', 'system'], ['system', 'human', 'system', 'engineering', 'testing', 'eps'], ['relation', 'user', 'perceived', 'response', 'time', 'error', 'measurement'], ['generation', 'random', 'binary', 'unordered', 'trees'], ['intersection', 'graph', 'paths', 'trees'], ['graph', 'minors', 'iv', 'widths', 'trees', 'well', 'quasi', 'ordering'], ['graph', 'minors', 'survey']]\n",
      "\n",
      "texts1: [['human', 'interface', 'computer'], ['survey', 'user', 'computer', 'system', 'response', 'time'], ['eps', 'user', 'interface', 'system'], ['system', 'human', 'system', 'eps'], ['user', 'response', 'time'], ['trees'], ['graph', 'trees'], ['graph', 'minors', 'trees'], ['graph', 'minors', 'survey']]\n",
      "\n",
      "ID:  {'computer': 0, 'human': 1, 'interface': 2, 'response': 3, 'survey': 4, 'system': 5, 'time': 6, 'user': 7, 'eps': 8, 'trees': 9, 'graph': 10, 'minors': 11}\n",
      "Freq:  {1: 2, 2: 2, 0: 2, 4: 2, 7: 3, 5: 3, 3: 2, 6: 2, 8: 2, 9: 3, 10: 3, 11: 2}\n",
      "\n",
      "corpus: [[(0, 1), (1, 1), (2, 1)], [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)], [(2, 1), (5, 1), (7, 1), (8, 1)], [(1, 1), (5, 2), (8, 1)], [(3, 1), (6, 1), (7, 1)], [(9, 1)], [(9, 1), (10, 1)], [(9, 1), (10, 1), (11, 1)], [(4, 1), (10, 1), (11, 1)]]\n",
      "TFIDF矩阵: [[(0, 0.5773502691896257), (1, 0.5773502691896257), (2, 0.5773502691896257)], [(0, 0.44424552527467476), (3, 0.44424552527467476), (4, 0.44424552527467476), (5, 0.3244870206138555), (6, 0.44424552527467476), (7, 0.3244870206138555)], [(2, 0.5710059809418182), (5, 0.4170757362022777), (7, 0.4170757362022777), (8, 0.5710059809418182)], [(1, 0.49182558987264147), (5, 0.7184811607083769), (8, 0.49182558987264147)], [(3, 0.6282580468670046), (6, 0.6282580468670046), (7, 0.45889394536615247)], [(9, 1.0)], [(9, 0.7071067811865475), (10, 0.7071067811865475)], [(9, 0.5080429008916749), (10, 0.5080429008916749), (11, 0.695546419520037)], [(4, 0.6282580468670046), (10, 0.45889394536615247), (11, 0.6282580468670046)]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 9.7702928e-03,  8.1651136e-03,  1.2809705e-03,  5.0975773e-03,\n",
       "         1.4081288e-03, -6.4551616e-03, -1.4280510e-03,  6.4491653e-03,\n",
       "        -4.6173073e-03, -3.9930656e-03,  4.9244044e-03,  2.7130984e-03,\n",
       "        -1.8479753e-03, -2.8769446e-03,  6.0107303e-03, -5.7167388e-03,\n",
       "        -3.2367038e-03, -6.4878250e-03, -4.2346334e-03, -8.5809948e-03,\n",
       "        -4.4697905e-03, -8.5112313e-03,  1.4037776e-03, -8.6181974e-03,\n",
       "        -9.9166557e-03, -8.2016252e-03, -6.7726658e-03,  6.6805840e-03,\n",
       "         3.7845564e-03,  3.5616636e-04, -2.9579829e-03, -7.4283220e-03,\n",
       "         5.3341867e-04,  4.9989222e-04,  1.9561767e-04,  8.5259438e-04,\n",
       "         7.8633073e-04, -6.8161491e-05, -8.0070542e-03, -5.8702733e-03,\n",
       "        -8.3829118e-03, -1.3120436e-03,  1.8206357e-03,  7.4171280e-03,\n",
       "        -1.9634271e-03, -2.3252917e-03,  9.4871549e-03,  7.9703328e-05,\n",
       "        -2.4045228e-03,  8.6048460e-03,  2.6870037e-03, -5.3439736e-03,\n",
       "         6.5881060e-03,  4.5101522e-03, -7.0544672e-03, -3.2317400e-04,\n",
       "         8.3448651e-04,  5.7473565e-03, -1.7176557e-03, -2.8065301e-03,\n",
       "         1.7484308e-03,  8.4717036e-04,  1.1928272e-03, -2.6342822e-03,\n",
       "        -5.9857843e-03,  7.3229838e-03,  7.5873756e-03,  8.2963565e-03,\n",
       "        -8.5988473e-03,  2.6364254e-03, -3.5599638e-03,  9.6204039e-03,\n",
       "         2.9037667e-03,  4.6411133e-03,  2.3856140e-03,  6.6084769e-03,\n",
       "        -5.7432912e-03,  7.8944108e-03, -2.4109220e-03, -4.5618867e-03,\n",
       "        -2.0609903e-03,  9.7335577e-03, -6.8565919e-03, -2.1917201e-03,\n",
       "         7.0009995e-03, -5.5749417e-05, -6.2949681e-03, -6.3935257e-03,\n",
       "         8.9403940e-03,  6.4295745e-03,  4.7735930e-03, -3.2620477e-03,\n",
       "        -9.2676207e-03,  3.7868882e-03,  7.1605491e-03, -5.6328895e-03,\n",
       "        -7.8650145e-03, -2.9727411e-03, -4.9318983e-03, -2.3151112e-03],\n",
       "       [ 7.0871473e-03, -1.5683782e-03,  7.9461364e-03, -9.4874427e-03,\n",
       "        -8.0296379e-03, -6.6422895e-03, -4.0041069e-03,  4.9910326e-03,\n",
       "        -3.8136279e-03, -8.3215833e-03,  8.4132208e-03, -3.7471871e-03,\n",
       "         8.6089820e-03, -4.8962692e-03,  3.9189272e-03,  4.9236091e-03,\n",
       "         2.3943025e-03, -2.8213640e-03,  2.8496354e-03, -8.2571078e-03,\n",
       "        -2.7652937e-03, -2.5905678e-03,  7.2491039e-03, -3.4629786e-03,\n",
       "        -6.5992209e-03,  4.3399399e-03, -4.7540484e-04, -3.5954388e-03,\n",
       "         6.8824128e-03,  3.8715161e-03, -3.8985382e-03,  7.7237905e-04,\n",
       "         9.1438834e-03,  7.7564754e-03,  6.3607404e-03,  4.6693156e-03,\n",
       "         2.3858545e-03, -1.8414279e-03, -6.3720327e-03, -2.9998334e-04,\n",
       "        -1.5642069e-03, -5.7058921e-04, -6.2630447e-03,  7.4330512e-03,\n",
       "        -6.5910248e-03, -7.2386782e-03, -2.7575779e-03, -1.5144736e-03,\n",
       "        -7.6353899e-03,  6.9955905e-04, -5.3253169e-03, -1.2739648e-03,\n",
       "        -7.3665036e-03,  1.9612678e-03,  3.2734126e-03, -2.4741203e-05,\n",
       "        -5.4490739e-03, -1.7256952e-03,  7.0866016e-03,  3.7357579e-03,\n",
       "        -8.8817989e-03, -3.4116022e-03,  2.3567537e-03,  2.1376403e-03,\n",
       "        -9.4648376e-03,  4.5697815e-03, -8.6582452e-03, -7.3883547e-03,\n",
       "         3.4832379e-03, -3.4728234e-03,  3.5656209e-03,  8.8950340e-03,\n",
       "        -3.5753339e-03,  9.3197320e-03,  1.7111641e-03,  9.8462272e-03,\n",
       "         5.7051540e-03, -9.1497740e-03, -3.3269732e-03,  6.5306681e-03,\n",
       "         5.6031067e-03,  8.7057864e-03,  6.9263605e-03,  8.0408510e-03,\n",
       "        -9.8231193e-03,  4.2975070e-03, -5.0308690e-03,  3.5132242e-03,\n",
       "         6.0578999e-03,  4.3924102e-03,  7.5100451e-03,  1.4993446e-03,\n",
       "        -1.2642510e-03,  5.7697659e-03, -5.6368350e-03,  3.7106704e-05,\n",
       "         9.4556073e-03, -5.4809595e-03,  3.8159816e-03, -8.1130704e-03],\n",
       "       [-5.1577436e-03, -6.6702794e-03, -7.7790986e-03,  8.3131464e-03,\n",
       "        -1.9829201e-03, -6.8569588e-03, -4.1555981e-03,  5.1456233e-03,\n",
       "        -2.8699716e-03, -3.7507527e-03,  1.6218971e-03, -2.7771019e-03,\n",
       "        -1.5848217e-03,  1.0748033e-03, -2.9788127e-03,  8.5217617e-03,\n",
       "         3.9120731e-03, -9.9617615e-03,  6.2614209e-03, -6.7562214e-03,\n",
       "         7.6965551e-04,  4.4055167e-03, -5.1048612e-03, -2.1112841e-03,\n",
       "         8.0978349e-03, -4.2450288e-03, -7.6384838e-03,  9.2606070e-03,\n",
       "        -2.1561245e-03, -4.7208075e-03,  8.5732946e-03,  4.2845840e-03,\n",
       "         4.3260953e-03,  9.2872158e-03, -8.4555410e-03,  5.2568498e-03,\n",
       "         2.0399450e-03,  4.1894992e-03,  1.6983944e-03,  4.4654319e-03,\n",
       "         4.4875946e-03,  6.1062989e-03, -3.2030295e-03, -4.5770612e-03,\n",
       "        -4.2664065e-04,  2.5344712e-03, -3.2641180e-03,  6.0594808e-03,\n",
       "         4.1553383e-03,  7.7668522e-03,  2.5700203e-03,  8.1190439e-03,\n",
       "        -1.3876136e-03,  8.0802785e-03,  3.7180968e-03, -8.0496678e-03,\n",
       "        -3.9347606e-03, -2.4725979e-03,  4.8944671e-03, -8.7241287e-04,\n",
       "        -2.8317324e-03,  7.8359870e-03,  9.3256142e-03, -1.6153983e-03,\n",
       "        -5.1607513e-03, -4.7031282e-03, -4.8474614e-03, -9.6056210e-03,\n",
       "         1.3724195e-03, -4.2261453e-03,  2.5274432e-03,  5.6161173e-03,\n",
       "        -4.0670903e-03, -9.5993746e-03,  1.5471478e-03, -6.7020725e-03,\n",
       "         2.4959005e-03, -3.7817324e-03,  7.0804814e-03,  6.4040697e-04,\n",
       "         3.5619752e-03, -2.7399310e-03, -1.7110463e-03,  7.6550203e-03,\n",
       "         1.4080878e-03, -5.8521517e-03, -7.8367768e-03,  1.2330448e-03,\n",
       "         6.4565083e-03,  5.5579669e-03, -8.9796642e-03,  8.5946647e-03,\n",
       "         4.0481547e-03,  7.4717780e-03,  9.7491713e-03, -7.2917030e-03,\n",
       "        -9.0425937e-03,  5.8376994e-03,  9.3939463e-03,  3.5079459e-03]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "from gensim import models\n",
    "\n",
    "documents = [\"Human machine interface for lab abc computer applications\",\n",
    "             \"A survey of user opinion of computer system response time\",\n",
    "             \"The EPS user interface management system\",\n",
    "             \"System and human system engineering testing of EPS\",\n",
    "             \"Relation of user perceived response time to error measurement\",\n",
    "             \"The generation of random binary unordered trees\",\n",
    "             \"The intersection graph of paths in trees\",\n",
    "             \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "             \"Graph minors A survey\"]\n",
    "\n",
    "# 去掉停用词\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist] for document in documents]\n",
    "print(\"texts: {}\".format(texts))\n",
    "\n",
    "dictionary = corpora.Dictionary(texts)   # 生成词典\n",
    "# 去掉出现少于两次的单词，去掉出现多于5次的单词，剩下的单词保留前100个\n",
    "dictionary.filter_extremes(no_below = 2, no_above = 5, keep_n = 100)\n",
    "texts1 = [[word for word in text if word in dictionary.token2id] for text in texts] # 更新texts\n",
    "print(\"\\ntexts1: {}\".format(texts1))\n",
    "print(\"\\nID: \", dictionary.token2id) # diction.token2id 存放的是单词-id key-value对\n",
    "print(\"Freq: \", dictionary.dfs) # diction.dfs 存放的是单词的出现频率\n",
    "\n",
    "# 1. 下面是用TF-IDF模型进行编码\n",
    "# 参考资料1：https://zhuanlan.zhihu.com/p/37175253\n",
    "# 参考资料2：https://www.cnblogs.com/keye/p/9190304.html\n",
    "\n",
    "# 建立语料库\n",
    "corpus = [dictionary.doc2bow(text) for text in texts] # 将文本数据转为id和频率数据（主要看dic的状态，texts不更新结果也一样）\n",
    "print(\"\\ncorpus: {}\".format(corpus))\n",
    "\n",
    "# 建立TF-IDF模型并生成矩阵\n",
    "tfidf_model = models.TfidfModel(corpus) # 训练TF-IDF模型，这个模型可以保存，详情见参考资料\n",
    "corpus_tfidf = tfidf_model[corpus] # 进行预测，获得TF-IDF矩阵，但是是个迭代器类型，只能用for来把每个样本的向量取出\n",
    "# 注意：上面这个预测过程不仅仅可以预测原数据，也可以预测别的数据，只要保证数据格式符合要求，且其映射成的字典需与模型训练集的相同\n",
    "print(\"TFIDF矩阵: {}\".format([v for v in corpus_tfidf]))\n",
    "\n",
    "# 2. 下面是用work2vec方法进行编码\n",
    "# 关于使用方法的详情，请见官方文档：https://radimrehurek.com/gensim/models/word2vec.html\n",
    "model = models.word2vec.Word2Vec(texts1, min_count=1) # 训练模型，输入的是分词的结果，参数细节见https://blog.csdn.net/u011748542/article/details/85880852\n",
    "model.wv.most_similar(\"user\",topn=10) # 计算训练集见过的词中与输入词的相似度，并降序排列取出前十个(输入词必须见过)\n",
    "model.wv.similarity('user', 'computer') # 计算两个输入词的相似性（输入词必须都见过）\n",
    "# model.wv.most_similar(positive=['woman', 'king'], negative=['man'], topn=1) # 猜词，结果是queen，这个不使用前面的数据了\n",
    "model.wv[texts1[0]].mean(axis = 1) # 测试模型，输入的词必须是训练过的，这里输入第一个样本的分词结果，得到第一个样本的全部词向量，然后做平均"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 使用nn.embedding+预训练处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用于深度学习NLP问题，纯词向量特征，每个词一个向量后pooling在一起"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PackedSequence(data=tensor([[1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [3],\n",
      "        [3],\n",
      "        [4],\n",
      "        [4],\n",
      "        [5],\n",
      "        [5],\n",
      "        [6],\n",
      "        [6],\n",
      "        [7],\n",
      "        [7]]), batch_sizes=tensor([2, 2, 2, 2, 2, 2, 1]), sorted_indices=None, unsorted_indices=None)\n",
      "PackedSequence(data=tensor([[ 0.1443,  0.0625, -0.0232,  0.1436,  0.1275],\n",
      "        [ 0.2047,  0.1032,  0.0009,  0.2001,  0.1720],\n",
      "        [ 0.2918,  0.1329, -0.0132,  0.2646,  0.2305],\n",
      "        [ 0.3570,  0.1644,  0.0121,  0.3265,  0.2902],\n",
      "        [ 0.4013,  0.1807,  0.0043,  0.3498,  0.3163],\n",
      "        [ 0.4515,  0.1960,  0.0237,  0.3876,  0.3774],\n",
      "        [ 0.4726,  0.2066,  0.0198,  0.3947,  0.3901],\n",
      "        [ 0.5081,  0.2103,  0.0323,  0.4091,  0.4491],\n",
      "        [ 0.5179,  0.2178,  0.0305,  0.4110,  0.4556],\n",
      "        [ 0.5428,  0.2147,  0.0372,  0.4115,  0.5099],\n",
      "        [ 0.5474,  0.2205,  0.0364,  0.4120,  0.5132],\n",
      "        [ 0.5649,  0.2140,  0.0388,  0.4063,  0.5607],\n",
      "        [ 0.5669,  0.2188,  0.0385,  0.4065,  0.5624]], grad_fn=<CatBackward>), batch_sizes=tensor([2, 2, 2, 2, 2, 2, 1]), sorted_indices=None, unsorted_indices=None) \n",
      "\n",
      "\n",
      "tensor([[[ 0.1443,  0.0625, -0.0232,  0.1436,  0.1275],\n",
      "         [ 0.2918,  0.1329, -0.0132,  0.2646,  0.2305],\n",
      "         [ 0.4013,  0.1807,  0.0043,  0.3498,  0.3163],\n",
      "         [ 0.4726,  0.2066,  0.0198,  0.3947,  0.3901],\n",
      "         [ 0.5179,  0.2178,  0.0305,  0.4110,  0.4556],\n",
      "         [ 0.5474,  0.2205,  0.0364,  0.4120,  0.5132],\n",
      "         [ 0.5669,  0.2188,  0.0385,  0.4065,  0.5624]],\n",
      "\n",
      "        [[ 0.2047,  0.1032,  0.0009,  0.2001,  0.1720],\n",
      "         [ 0.3570,  0.1644,  0.0121,  0.3265,  0.2902],\n",
      "         [ 0.4515,  0.1960,  0.0237,  0.3876,  0.3774],\n",
      "         [ 0.5081,  0.2103,  0.0323,  0.4091,  0.4491],\n",
      "         [ 0.5428,  0.2147,  0.0372,  0.4115,  0.5099],\n",
      "         [ 0.5649,  0.2140,  0.0388,  0.4063,  0.5607],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],\n",
      "       grad_fn=<TransposeBackward0>) \n",
      "\n",
      "\n",
      "tensor([[[0.3482, 0.6518],\n",
      "         [0.3367, 0.6633],\n",
      "         [0.3292, 0.6708],\n",
      "         [0.3260, 0.6740],\n",
      "         [0.3256, 0.6744],\n",
      "         [0.3267, 0.6733],\n",
      "         [0.3285, 0.6715]],\n",
      "\n",
      "        [[0.3417, 0.6583],\n",
      "         [0.3319, 0.6681],\n",
      "         [0.3276, 0.6724],\n",
      "         [0.3266, 0.6734],\n",
      "         [0.3275, 0.6725],\n",
      "         [0.3292, 0.6708],\n",
      "         [0.3580, 0.6420]]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data.dataset as Dataset\n",
    "import torch.utils.data.dataloader as DataLoader\n",
    "# 看下面内容前，一定先看参考资料：https://blog.csdn.net/lssc4205/article/details/79474735，弄清楚三个pad函数是干嘛的\n",
    "\n",
    "# 1. 假设我们已经完成了所有的分词工作，并且要使用预训练好的大型embedding矩阵进行编码\n",
    "# 注：（其实可以将nn.Embedding作为层放到网络中随模型一起进行有监督的训练来编码，那样最原始的输入不需要embedding，但暂时不讨论这个）\n",
    "# 2. 假设我们获得了大型embedding矩阵的词字典及每个词的索引位置，并将自己分好词的数据集中每个词转换为对应的词索引\n",
    "# 3. 文本转为索引后，经常面临不同batch维度不一致问题，导致数据不能输入模型，下面是一般的处理过程：\n",
    "\n",
    "# 3.1 首先把词索引矩阵list一下，变成下面的列表型，每个元素都是一个样本的词向量索引列表，然后按索引长度对样本降序排序：（降序的原因在后面）\n",
    "train_x = [torch.tensor([0, 1, 3]),\n",
    "           torch.tensor([2, 3]),\n",
    "           torch.tensor([3])]\n",
    "\n",
    "# 3.2 然后使用pad_sequence对长度不齐的部分进行数据补值，默认值自选padding_value\n",
    "train_x1 = nn.utils.rnn.pad_sequence(train_x, batch_first=True, padding_value=0) # 填充值可以随便选，后面不会被计算\n",
    "\n",
    "# 3.3 维度问题解决后，进行假装进行embedding\n",
    "weight = torch.FloatTensor([[1, 2.3, 3], \n",
    "                            [4, 5.1, 6.3],\n",
    "                            [0.3,4.5,2.4],\n",
    "                            [3, 4, 5.0]]) # 假装weight就是大型矩阵\n",
    "embedding = nn.Embedding.from_pretrained(weight) # 直接承接预训练结果\n",
    "embedded = embedding(train_x1) # 对填充后的tensor列表进行embedding操作，结果集中原本不存在的部分也被编码了，但后面会去除\n",
    "\n",
    "# 3.4 关键步骤：对上述结果压缩为PackedSequence类型，第二个参数是每个样本的词个数组成的列表，必须用最开始数据的长度列表（压缩的原因见最后）\n",
    "padded_data = nn.utils.rnn.pack_padded_sequence(embedded, [len(data) for data in train_x], batch_first=True)\n",
    "# 解答：样本按词数降序排序的原因就是为了在告诉函数长度列表后，他能知道每个seq中哪些样本的词是被填补的词，这部分是不会输入模型的\n",
    "# 注意：其实到3.4为止，其结果就可以被RNN和LSTM给接受了（attention暂时不知)，可以直接输入模型，模型自己就知道该跑哪些部分，但是线性层不可以使用\n",
    "\n",
    "# 3.5 将数据转回tensor格式，所有填补的词的embedding向量在这里都是0向量\n",
    "packed_data = nn.utils.rnn.pad_packed_sequence(padded_data, batch_first=True) # 这个结果可以输入模型了\n",
    "# 注：压缩原因：一般为了避免不必要的存储和计算（填充词即便是0也会占资源，调用计算），在RNN和LSTM模型中，不把3.5后结果扔进去，而是用3.4后的结果，填充的部分自动忽略\n",
    "# 当从循环网络出来后接线性层时，再把得到的结果经过3.5过程转化为tensor；如果不是RNN或LSTM，就不一定能这样做了\n",
    "\n",
    "\n",
    "#  以下步骤待定，不一定采用，下次再写\n",
    "class MyData(Dataset.Dataset):\n",
    "    def __init__(self, train_x):\n",
    "        self.train_x = train_x\n",
    "    def __len__(self):\n",
    "        return len(self.train_x)\n",
    "    def __getitem__(self, item):\n",
    "        return self.train_x[item]\n",
    "\n",
    "def collate_fn(train_data):\n",
    "    train_data.sort(key = lambda data: len(data), reverse = True)\n",
    "    data_length = [len(data) for data in train_data]\n",
    "    train_data = nn.utils.rnn.pad_sequence(train_data, batch_first=True, padding_value=0) # padding过程\n",
    "    return train_data.unsqueeze(-1), data_length\n",
    "\n",
    "train_data = MyData(train_x)\n",
    "train_dataloader = DataLoader.DataLoader(train_data, batch_size=2, collate_fn=collate_fn)\n",
    "\n",
    "# padding后的结果\n",
    "# for data, length in train_dataloader:\n",
    "#     print(data)\n",
    "#     print(length)\n",
    "# padding后会有资源浪费，继续padded可以让每次循环输入后没有0填充值（必须再padding后操作）\n",
    "\n",
    "net = nn.LSTM(1, 5, batch_first=True) # 简单的模型\n",
    "Linear = nn.Linear(5, 2)\n",
    "for data, length in train_dataloader:\n",
    "    data = nn.utils.rnn.pack_padded_sequence(data, length, batch_first=True) # padded操作\n",
    "    print(data) # padded后的数据\n",
    "    output, hidden = net(data.float()) # 将padded后的数据输入模型得到output，这个padded后的输入仅能在LSTM或RNN层输入，不能输入普通线性层\n",
    "    print(output,\"\\n\\n\")\n",
    "    output, out_len = nn.utils.rnn.pad_packed_sequence(output, batch_first=True) # 将output转回正常形态以方便接下来接入线性层\n",
    "    print(output,\"\\n\\n\") # 普通状态的output展示\n",
    "    print(F.softmax(Linear(output), dim = 2)) # 输出概率结果\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
